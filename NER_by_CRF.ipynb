{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_by_CRF_Cantemist_Competicion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5Mt4hDPDvdSb",
        "qL3JwriByPih",
        "VePnO1kvcJFs",
        "NpaPaCT41SnM",
        "L-mN5DYWZ0uh",
        "Uau3zx4dqG7b",
        "BvG_lW-ZxjzP",
        "_u9z-qyIZno7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fju-V7DpAgm",
        "colab_type": "text"
      },
      "source": [
        "# **NER_by_CRF**\n",
        "\n",
        "## **Author:** Gema De Vargas Romero\n",
        "\n",
        "## **Master Thesis:** \"Development of a Named Entity Recognition System to automatically assign tumor morphology entity mentions to health-related documents in Spanish.\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05N_SwgGTL6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "77975045-88c6-4061-8874-a41f86b40ec5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "path='drive/My Drive/Ejemplos NER - TFM/'\n",
        "!ls 'drive/My Drive/Ejemplos NER - TFM/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            " bert\n",
            " check_results2.ipynb\n",
            " check_results.ipynb\n",
            " data\n",
            " dev_set\n",
            " dev_set2\n",
            "'Dictionary based NER (spacy).ipynb'\n",
            "'Ehealth_Dictionary based NER (spacy).ipynb'\n",
            " last_step_cantemist.ipynb\n",
            " last_step_cantemist_TEST.ipynb\n",
            " NER_by_BERT_Cantemist_BIOESV.ipynb\n",
            " NER_by_BERT_Cantemist_Competicion.ipynb\n",
            " NER_by_BERT_Cantemist.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist_BIOESV_2.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist_BIOESV.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist_Competicion.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist.ipynb\n",
            " NER_by_CRF_Cantemist_Competicion.ipynb\n",
            " NER_by_CRF_Cantemist.ipynb\n",
            " NER_by_CRF_Ehealth.ipynb\n",
            " NER_by_CRF.ipynb\n",
            " Preprocessing_NER_Cantemist.ipynb\n",
            " resources\n",
            " results_bert\n",
            " results_bert2\n",
            " results_BILSTM_ap1\n",
            " results_BILSTM_ap2\n",
            " results_BILSTM_ap3\n",
            " results_CRF\n",
            " sample_set\n",
            " Scielo+Wiki_skipgram_cased.bin\n",
            " Scielo+Wiki_skipgram_cased.vec\n",
            " test-background-set-to-publish\n",
            " test_set\n",
            " test_set_predictions\n",
            " train_set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mt4hDPDvdSb",
        "colab_type": "text"
      },
      "source": [
        "## **Loading libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scn6jrRSUoKx",
        "colab_type": "text"
      },
      "source": [
        "First, we must load the libraries that we will use in this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtRt1ONNabh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3835f356-142e-4f6a-deb8-f1be01e43aeb"
      },
      "source": [
        "!pip install sklearn-crfsuite\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite.metrics import flat_f1_score\n",
        "from sklearn_crfsuite.metrics import flat_precision_score\n",
        "from sklearn_crfsuite.metrics import flat_recall_score\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzcWUWl2aWqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "959221d1-c780-4f20-dbfb-8c74ff58d862"
      },
      "source": [
        "# Library spacy\n",
        "!pip install -U spacy \n",
        "#!python -m spacy validate\n",
        "!python -m spacy download es_core_news_lg\n",
        "\n",
        "import spacy\n",
        "\n",
        "# nlp = spacy.load(\"es\") # no longer works with updated version of spacy 2.3.1\n",
        "import es_core_news_lg\n",
        "nlp = es_core_news_lg.load()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/b5/c7a92c7ce5d4b353b70b4b5b4385687206c8b230ddfe08746ab0fd310a3a/spacy-2.3.2-cp36-cp36m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.2.0)\n",
            "Collecting thinc==7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.2 thinc-7.4.1\n",
            "Collecting es_core_news_lg==2.3.1\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-2.3.1/es_core_news_lg-2.3.1.tar.gz (573.1MB)\n",
            "\u001b[K     |████████████████████████████████| 573.1MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from es_core_news_lg==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (49.2.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (0.7.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.1.0)\n",
            "Building wheels for collected packages: es-core-news-lg\n",
            "  Building wheel for es-core-news-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-lg: filename=es_core_news_lg-2.3.1-cp36-none-any.whl size=573139081 sha256=90577aabb67f6cc06f7c5160642e00913b1bb2453b11f4cb4912e556643bed92\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lzrypxne/wheels/48/59/33/558e7f48e924c6cac0cbd3679ee7c84f5ae02964c335232e5a\n",
            "Successfully built es-core-news-lg\n",
            "Installing collected packages: es-core-news-lg\n",
            "Successfully installed es-core-news-lg-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZoodfUmfQuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8d96e2b4-94a6-4a79-9b19-e8894f01716d"
      },
      "source": [
        "!pip install unidecode\n",
        "import unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tagsZfDrd1lM"
      },
      "source": [
        "## **Read the files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FpxWth4pd1lN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ff666242-fa4f-401e-d2d3-a65caef4b192"
      },
      "source": [
        "!ls 'drive/My Drive/Ejemplos NER - TFM/data'\n",
        "import pickle as pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_data_complete.csv\tfiles_txt_dev\t     sentences_dev_by_cc2\n",
            "df_data_dev2_2.csv\tfiles_txt_test\t     sentences_test\n",
            "df_data_dev2.csv\tfiles_txt_test_true  sentences_test_by_cc\n",
            "df_data_test.csv\tsentences_dev\t     sentences_test_true\n",
            "df_data_test_true2.csv\tsentences_dev2\t     sentences_test_true_by_cc\n",
            "df_data_train2.csv\tsentences_dev_by_cc  sentences_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj1_4U9IeC-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "80cbc1b3-bf8d-46f6-ba63-c00e8cf0e560"
      },
      "source": [
        "# Train dataset\n",
        "with open(path+'data/sentences_train', 'rb') as file: \n",
        "  sentences_train = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "df_data_train2 = pd.read_csv(path+'data/df_data_train2.csv')\n",
        "print(sentences_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ANAMNESIS', 'NOUN', 'O', 0), ('\\n', 'SPACE', 'O', 9), ('Mujer', 'NOUN', 'O', 10), ('de', 'ADP', 'O', 16), ('67', 'NUM', 'O', 19), ('años', 'NOUN', 'O', 22), ('con', 'ADP', 'O', 27), ('antecedentes', 'NOUN', 'O', 31), ('personales', 'ADJ', 'O', 44), ('de', 'ADP', 'O', 55), ('hipotiroidismo', 'NOUN', 'O', 58), ('en', 'ADP', 'O', 73), ('tratamiento', 'NOUN', 'O', 76), ('con', 'ADP', 'O', 88), ('levotiroxina', 'NOUN', 'O', 92), ('y', 'CCONJ', 'O', 105), ('fumadora', 'ADJ', 'O', 107), ('activa', 'ADJ', 'O', 116), ('de', 'ADP', 'O', 123), ('12.5', 'NUM', 'O', 126), ('paquetes', 'NOUN', 'O', 131), ('/', 'PUNCT', 'O', 139), ('año', 'NOUN', 'O', 140), ('.', 'PUNCT', 'O', 143)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_LAMsMgeIY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b3df974a-5907-41b6-c7c0-e2f34bf53d3a"
      },
      "source": [
        "# Development dataset 1\n",
        "with open(path+'data/sentences_dev', 'rb') as file: \n",
        "  sentences_dev = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'data/sentences_dev_by_cc', 'rb') as file: \n",
        "  sentences_dev_by_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "df_data_dev2 = pd.read_csv(path+'data/df_data_dev2.csv')\n",
        "\n",
        "print(sentences_dev_by_cc[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Anamnesis', 'NOUN', 'O', 0), ('\\n', 'SPACE', 'O', 9), ('Varón', 'PROPN', 'O', 10), ('de', 'ADP', 'O', 16), ('74', 'NUM', 'O', 19), ('años', 'NOUN', 'O', 22), (',', 'PUNCT', 'O', 26), ('exfumador', 'NOUN', 'O', 28), ('desde', 'ADP', 'O', 38), ('hace', 'AUX', 'O', 44), ('15', 'NUM', 'O', 49), ('años', 'NOUN', 'O', 52), (',', 'PUNCT', 'O', 56), ('con', 'ADP', 'O', 58), ('único', 'ADJ', 'O', 62), ('antecedente', 'NOUN', 'O', 68), ('de', 'ADP', 'O', 80), ('hipertensión', 'NOUN', 'O', 83), (',', 'PUNCT', 'O', 95), ('dislipemia', 'NOUN', 'O', 97), ('y', 'CCONJ', 'O', 108), ('apendicectomizado', 'ADJ', 'O', 110), (';', 'PUNCT', 'O', 127), ('se', 'PRON', 'O', 129), ('diagnostica', 'VERB', 'O', 132), ('en', 'ADP', 'O', 144), ('marzo', 'INTJ', 'O', 147), ('de', 'ADP', 'O', 153), ('2013', 'NUM', 'O', 156), ('de', 'ADP', 'O', 161), ('carcinoma', 'INTJ', 'B-MOR', 164), ('de', 'ADP', 'I-MOR', 174), ('células', 'NOUN', 'I-MOR', 177), ('transicionales', 'ADJ', 'I-MOR', 185), ('de', 'ADP', 'I-MOR', 200), ('vejiga', 'PROPN', 'I-MOR', 203), ('E-IV', 'PROPN', 'I-MOR', 210), ('(', 'PUNCT', 'E-MOR', 215), ('pulmonares', 'ADJ', 'O', 216), ('y', 'CCONJ', 'O', 227), ('óseas', 'ADJ', 'O', 229), (')', 'PUNCT', 'O', 234), ('.', 'PUNCT', 'O', 235)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ImCDQ44Bd1lP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0dcf1906-09de-459f-da3d-f82d518cf161"
      },
      "source": [
        "# Development dataset 2\n",
        "with open(path+'data/sentences_dev2', 'rb') as file: \n",
        "  sentences_dev2 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'data/sentences_dev_by_cc2', 'rb') as file: \n",
        "  sentences_dev_by_cc2 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "df_data_dev2_2 = pd.read_csv(path+'data/df_data_dev2_2.csv')\n",
        "\n",
        "print(sentences_dev_by_cc2[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Anamnesis', 'NOUN', 'O', 0), ('\\n', 'SPACE', 'O', 9), ('Mujer', 'NOUN', 'O', 10), ('de', 'ADP', 'O', 16), ('60', 'NUM', 'O', 19), ('años', 'NOUN', 'O', 22), ('diagnosticada', 'ADJ', 'O', 27), ('de', 'ADP', 'O', 41), ('enfermedad', 'NOUN', 'O', 44), ('pulmonar', 'ADJ', 'O', 55), ('obstructiva', 'ADJ', 'O', 64), ('crónica', 'ADJ', 'O', 76), ('y', 'CCONJ', 'O', 84), ('trastorno', 'NOUN', 'O', 86), ('bipolar', 'ADJ', 'O', 96), ('de', 'ADP', 'O', 104), ('años', 'NOUN', 'O', 107), ('de', 'ADP', 'O', 112), ('evolución', 'NOUN', 'O', 115), (',', 'PUNCT', 'O', 124), ('en', 'ADP', 'O', 126), ('tratamiento', 'NOUN', 'O', 129), ('con', 'ADP', 'O', 141), ('carbamazepina', 'NOUN', 'O', 145), ('hasta', 'ADP', 'O', 159), ('la', 'DET', 'O', 165), ('fecha', 'NOUN', 'O', 168), (',', 'PUNCT', 'O', 173), ('sin', 'ADP', 'O', 175), ('otros', 'DET', 'O', 179), ('antecedentes', 'NOUN', 'O', 185), ('personales', 'ADJ', 'O', 198), ('de', 'ADP', 'O', 209), ('interés', 'NOUN', 'O', 212), ('.', 'PUNCT', 'O', 219)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANP2WPx49-S_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d90b417f-4c88-4e7f-9887-827174aaa300"
      },
      "source": [
        "# TEST AND BACKGROUND FILES:\n",
        "with open(path+'data/sentences_test', 'rb') as file: \n",
        "  sentences_test = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'data/sentences_test_by_cc', 'rb') as file: \n",
        "  sentences_test_by_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "df_data_test = pd.read_csv(path+'data/df_data_test.csv')\n",
        "\n",
        "print(sentences_test_by_cc[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Paciente', 'PROPN', 0), ('mujer', 'NOUN', 9), (',', 'PUNCT', 14), ('75', 'NUM', 16), ('años', 'NOUN', 19), ('consulta', 'VERB', 24), ('el', 'DET', 33), ('4-6-2003', 'NOUN', 36), (',', 'PUNCT', 44), ('refiriendo', 'VERB', 46), ('como', 'SCONJ', 57), ('antecedentes', 'NOUN', 62), ('personales', 'ADJ', 75), (':', 'PUNCT', 85), ('Alergia', 'PROPN', 87), ('a', 'ADP', 95), ('salicilatos', 'NOUN', 97), ('.', 'PUNCT', 108)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2UiX01Qm949",
        "colab_type": "text"
      },
      "source": [
        "## **Model 1: NER_by_CRF code:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgkShc8BaA1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_train_COPY = sentences_train.copy()\n",
        "\n",
        "sentences_dev_COPY = sentences_dev.copy()\n",
        "sentences_dev_by_cc_COPY = sentences_dev_by_cc.copy()\n",
        "\n",
        "sentences_dev2_COPY = sentences_dev2.copy()\n",
        "sentences_dev_by_cc2_COPY = sentences_dev_by_cc2.copy()\n",
        "\n",
        "sentences_test_COPY = sentences_test.copy()\n",
        "sentences_test_by_cc_COPY = sentences_test_by_cc.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws949UMKaAif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_word(w):\n",
        "  # 1st turn to lowercase\n",
        "  w = w.lower()\n",
        "  # 2nd remove accents and strange characters\n",
        "  w = unidecode.unidecode(w)\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lww0uOmvg59M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess = True\n",
        "\n",
        "if (preprocess==True):\n",
        "  sentences_train = [[(preprocess_word(w[0]),w[1],w[2],w[3]) for w in s] for s in sentences_train]\n",
        "\n",
        "  sentences_dev = [[(preprocess_word(w[0]),w[1],w[2],w[3]) for w in s] for s in sentences_dev]\n",
        "  sentences_dev_by_cc = [[[(preprocess_word(w[0]),w[1],w[2],w[3]) for w in s] for s in cc] for cc in sentences_dev_by_cc]\n",
        "\n",
        "  sentences_dev2 = [[(preprocess_word(w[0]),w[1],w[2],w[3]) for w in s] for s in sentences_dev2]\n",
        "  sentences_dev_by_cc2 = [[[(preprocess_word(w[0]),w[1],w[2],w[3]) for w in s] for s in cc] for cc in sentences_dev_by_cc2]\n",
        "\n",
        "  sentences_test = [[(preprocess_word(w[0]),w[1],w[2]) for w in s] for s in sentences_test]\n",
        "  sentences_test_by_cc = [[[(preprocess_word(w[0]),w[1],w[2]) for w in s] for s in cc] for cc in sentences_test_by_cc]\n",
        "\n",
        "\n",
        "else:\n",
        "  sentences_train = sentences_train_COPY\n",
        "\n",
        "  sentences_dev = sentences_dev_COPY\n",
        "  sentences_dev_by_cc = sentences_dev_by_cc_COPY\n",
        "\n",
        "  sentences_dev2 = sentences_dev2_COPY\n",
        "  sentences_dev_by_cc2 = sentences_dev_by_cc2_COPY\n",
        "\n",
        "  sentences_test = sentences_test_COPY\n",
        "  sentences_test_by_cc = sentences_test_by_cc_COPY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E4jo4zOWOKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "edeceb4f-4763-41a8-e997-dafc9f19b6f2"
      },
      "source": [
        "print(sentences_test_by_cc[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('anamnesis', 'NOUN', 'O', 0), ('\\n', 'SPACE', 'O', 9), ('se', 'PRON', 'O', 10), ('trata', 'VERB', 'O', 13), ('de', 'ADP', 'O', 19), ('un', 'DET', 'O', 22), ('paciente', 'NOUN', 'O', 25), ('de', 'ADP', 'O', 34), ('67', 'NUM', 'O', 37), ('anos', 'NOUN', 'O', 40), ('en', 'ADP', 'O', 45), ('el', 'DET', 'O', 48), ('momento', 'NOUN', 'O', 51), ('del', 'ADP', 'O', 59), ('diagnostico', 'NOUN', 'O', 63), (',', 'PUNCT', 'O', 74), ('con', 'ADP', 'O', 76), ('antecedentes', 'NOUN', 'O', 80), ('personales', 'ADJ', 'O', 93), ('a', 'ADP', 'O', 104), ('destacar', 'VERB', 'O', 106), ('de', 'ADP', 'O', 115), ('hipercolesterolemia', 'NOUN', 'O', 118), ('en', 'ADP', 'O', 138), ('tratamiento', 'NOUN', 'O', 141), ('con', 'ADP', 'O', 153), ('estatina', 'NOUN', 'O', 157), ('y', 'CCONJ', 'O', 166), ('alteracion', 'NOUN', 'O', 168), ('basal', 'ADJ', 'O', 179), ('de', 'ADP', 'O', 185), ('la', 'DET', 'O', 188), ('glucemia', 'NOUN', 'O', 191), ('en', 'ADP', 'O', 200), ('controles', 'NOUN', 'O', 203), (',', 'PUNCT', 'O', 212), ('exfumador', 'NOUN', 'O', 214), ('hace', 'AUX', 'O', 224), ('cinco', 'NUM', 'O', 229), ('anos', 'NOUN', 'O', 235), ('de', 'ADP', 'O', 240), ('24', 'NUM', 'O', 243), ('paquetes-ano', 'PROPN', 'O', 246), ('.', 'PUNCT', 'O', 258)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyjtvT1LuDFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn_crfsuite import CRF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSAdqfG7bhex",
        "colab_type": "text"
      },
      "source": [
        "### **Feature Preparation**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBoMMBEybmkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:], # last 3 characters of the word\n",
        "        'word[-2:]': word[-2:], # last 2 characters of the word\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True # Beggining of sentence\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label, start_pos in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label, start_pos in sent]\n",
        "\n",
        "def sent2start_pos(sent):\n",
        "    return [start_pos for token, postag, label, start_pos in sent]\n",
        "\n",
        "def sent2tokens_test(sent):\n",
        "    return [token for token, postag, start_pos in sent]\n",
        "\n",
        "def sent2start_pos_test(sent):\n",
        "    return [start_pos for token, postag, start_pos in sent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt15DXW1yA56",
        "colab_type": "text"
      },
      "source": [
        "#### **Train and development datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5m2zBp3WgzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN SET\n",
        "X_train = [sent2features(s) for s in sentences_train] # function called over every sentence in sentences\n",
        "y_train = [sent2labels(s) for s in sentences_train]\n",
        "\n",
        "# --------------------------------------\n",
        "\n",
        "# DEVELOPMENT SET 1 (done by clinical case)\n",
        "X_dev_cc = [[sent2features(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc]\n",
        "y_dev_cc = [[sent2labels(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc]\n",
        "\n",
        "start_char_dev_cc = [[sent2start_pos(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc]\n",
        "token_dev_cc = [[sent2tokens(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc]\n",
        "\n",
        "\n",
        "# DEVELOPMENT SET 1 (without considering clinical cases independently)\n",
        "X_dev = [sent2features(s) for s in sentences_dev]\n",
        "y_dev = [sent2labels(s) for s  in sentences_dev]\n",
        "\n",
        "# --------------------------------------\n",
        "\n",
        "# DEVELOPMENT SET 2 (done by clinical case)\n",
        "X_dev_cc2 = [[sent2features(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc2]\n",
        "y_dev_cc2 = [[sent2labels(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc2]\n",
        "\n",
        "start_char_dev_cc2 = [[sent2start_pos(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc2]\n",
        "token_dev_cc2 = [[sent2tokens(s) for s in sentences_cc] for sentences_cc in sentences_dev_by_cc2]\n",
        "\n",
        "# DEVELOPMENT SET 2 (without considering clinical cases independently)\n",
        "X_dev2 = [sent2features(s) for s in sentences_dev2]\n",
        "y_dev2 = [sent2labels(s) for s  in sentences_dev2]\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdcoi94U36yJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b5180fc3-6662-4075-ea6c-9683d62b9bd1"
      },
      "source": [
        "# checking\n",
        "print(\"Number of words in the first sentence of the first clinical case: %d\" %len(sentences_dev_by_cc[0][0]))\n",
        "x_aux = sent2features(sentences_dev_by_cc[0][0])\n",
        "\n",
        "# it creates a feature for every word in the sentence\n",
        "\n",
        "print(\"Number of features created from the first sentence: %d\" %len(x_aux))\n",
        "print(\"\\nFirst feature in first sentence:\")\n",
        "print(x_aux[0]) # Feature information of the next word at the beggining +1:postag. Ex. first word is 'En' BUT aux[0] contains info of 'la'\n",
        "\n",
        "y_aux = sent2labels(sentences_dev_by_cc[0][0])\n",
        "print(\"\\nNumber of labels created from the first sentence: %d\" %len(y_aux))\n",
        "print(\"\\nLabels in first sentence:\")\n",
        "print(y_aux)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in the first sentence of the first clinical case: 43\n",
            "Number of features created from the first sentence: 43\n",
            "\n",
            "First feature in first sentence:\n",
            "{'bias': 1.0, 'word.lower()': 'anamnesis', 'word[-3:]': 'sis', 'word[-2:]': 'is', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', 'BOS': True, '+1:word.lower()': '\\n', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'SPACE', '+1:postag[:2]': 'SP'}\n",
            "\n",
            "Number of labels created from the first sentence: 43\n",
            "\n",
            "Labels in first sentence:\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MOR', 'I-MOR', 'I-MOR', 'I-MOR', 'I-MOR', 'I-MOR', 'I-MOR', 'E-MOR', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL3JwriByPih",
        "colab_type": "text"
      },
      "source": [
        "#### **Test and background dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYfIvMgIyHAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST SET (done by clinical case)\n",
        "X_test_cc = [[sent2features(s) for s in sentences_cc] for sentences_cc in sentences_test_by_cc]\n",
        "start_char_test_cc = [[sent2start_pos_test(s) for s in sentences_cc] for sentences_cc in sentences_test_by_cc]\n",
        "token_test_cc = [[sent2tokens_test(s) for s in sentences_cc] for sentences_cc in sentences_test_by_cc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYMMST002ZSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "17d1d463-603f-49c6-ea32-572d2851844b"
      },
      "source": [
        "print(sentences_test_by_cc[1][1])\n",
        "print(start_char_test_cc[1][1])\n",
        "print(token_test_cc[1][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('en', 'ADP', 515), ('los', 'DET', 518), ('analisis', 'NOUN', 522), (',', 'PUNCT', 530), ('presentaba', 'AUX', 532), ('ligero', 'ADJ', 543), ('aumento', 'NOUN', 550), ('de', 'ADP', 558), ('la', 'DET', 561), ('cortisoluria', 'PROPN', 564), ('(', 'PUNCT', 577), ('284.5', 'SYM', 578), ('mcgr./24h', 'PROPN', 584), ('.', 'PUNCT', 593)]\n",
            "[515, 518, 522, 530, 532, 543, 550, 558, 561, 564, 577, 578, 584, 593]\n",
            "['en', 'los', 'analisis', ',', 'presentaba', 'ligero', 'aumento', 'de', 'la', 'cortisoluria', '(', '284.5', 'mcgr./24h', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VePnO1kvcJFs",
        "colab_type": "text"
      },
      "source": [
        "### **Train and evaluate the CRF model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDh-9H_Fbyvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crf = CRF(algorithm = 'lbfgs',\n",
        "         c1 = 0.1,\n",
        "         c2 = 0.1,\n",
        "         max_iterations = 100,\n",
        "         all_possible_transitions = False)\n",
        "\n",
        "crf.fit(X_train, y_train)\n",
        "\n",
        "# labels used in the classification report\n",
        "labels = ['B-MOR', 'I-MOR', 'E-MOR', 'S-MOR', 'V-MOR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpaPaCT41SnM",
        "colab_type": "text"
      },
      "source": [
        "##### **Predictions over train and development sets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-bzodSjrGt2",
        "colab_type": "text"
      },
      "source": [
        "**Predictions over validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Da7CPWfb4n8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "317f6fad-8228-41ae-f609-c86713d9e50a"
      },
      "source": [
        "#Predicting on the test set.\n",
        "y_pred = crf.predict(X_valid)\n",
        "# returns predicted labels\n",
        "\n",
        "f1_score_crf = flat_f1_score(y_valid, y_pred, average = 'micro', labels = labels)\n",
        "precision_crf = flat_precision_score(y_valid, y_pred, average = 'micro', labels = labels)\n",
        "recall_crf = flat_recall_score(y_valid, y_pred, average = 'micro', labels = labels)\n",
        "\n",
        "print(f1_score_crf)\n",
        "print(precision_crf)\n",
        "print(recall_crf)\n",
        "\n",
        "report = flat_classification_report(y_valid, y_pred, labels)\n",
        "print(report)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7656249999999999\n",
            "0.8249804228660924\n",
            "0.7142372881355932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-MOR       0.87      0.73      0.79       630\n",
            "       I-MOR       0.77      0.61      0.68      1032\n",
            "       E-MOR       0.79      0.66      0.72       629\n",
            "       S-MOR       0.88      0.91      0.90       658\n",
            "       V-MOR       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.82      0.71      0.77      2950\n",
            "   macro avg       0.66      0.58      0.62      2950\n",
            "weighted avg       0.82      0.71      0.76      2950\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2-Fr0QlkaWs",
        "colab_type": "text"
      },
      "source": [
        "**Predictions over development set 1**\n",
        "\n",
        "The predictions over the development set are obtained by clinical case. Therefore, loop over all clinical cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhuKFw1iIlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c7419432-d3ac-4f05-fc8e-4bada52f55d4"
      },
      "source": [
        "#Predicting on the development set.\n",
        "y_pred_dev = crf.predict(X_dev)\n",
        "\n",
        "f1_score_crf_dev = flat_f1_score(y_dev, y_pred_dev, average = 'micro', labels = labels)\n",
        "precision_crf_dev = flat_precision_score(y_dev, y_pred_dev, average = 'micro', labels = labels)\n",
        "recall_crf_dev = flat_recall_score(y_dev, y_pred_dev, average = 'micro', labels = labels)\n",
        "\n",
        "print(f1_score_crf_dev)\n",
        "print(precision_crf_dev)\n",
        "print(recall_crf_dev)\n",
        "\n",
        "report_dev = flat_classification_report(y_dev, y_pred_dev, labels)\n",
        "print(report_dev)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7371190528392895\n",
            "0.823481384715872\n",
            "0.6671517396481016\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-MOR       0.85      0.70      0.76      1639\n",
            "       I-MOR       0.81      0.57      0.67      2579\n",
            "       E-MOR       0.74      0.60      0.67      1634\n",
            "       S-MOR       0.89      0.86      0.88      1689\n",
            "       V-MOR       0.00      0.00      0.00        18\n",
            "\n",
            "   micro avg       0.82      0.67      0.74      7559\n",
            "   macro avg       0.66      0.55      0.59      7559\n",
            "weighted avg       0.82      0.67      0.73      7559\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSOuZtDkbLRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_words(tokens_sent,label_sent, true_label_sent, start_char_pos):\n",
        "  new_tok, new_lab, true_lab, new_start_pos = [], [], [], []\n",
        "\n",
        "  for tokens, labels, true_labels, start_chars in zip(tokens_sent, label_sent, true_label_sent, start_char_pos):\n",
        "    new_tok_aux, new_lab_aux, true_lab_aux, new_start_pos_aux = [], [], [], []\n",
        "    for token, label, true_label, start_char_i in zip(tokens, labels,true_labels,start_chars):\n",
        "      if token != \"PAD\":\n",
        "        new_tok_aux.append(token)\n",
        "        new_lab_aux.append(label)\n",
        "        true_lab_aux.append(true_label)\n",
        "        new_start_pos_aux.append(start_char_i)\n",
        "\n",
        "    new_lab.append(new_lab_aux)\n",
        "    true_lab.append(true_lab_aux)\n",
        "    new_tok.append(new_tok_aux)\n",
        "    new_start_pos.append(new_start_pos_aux)\n",
        "\n",
        "  return new_tok, new_lab, true_lab, new_start_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2GeQpkldIxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tokens_cc, new_labels_cc, true_labels_cc, new_start_pos_cc = [], [], [], []\n",
        "new_tokens_all_dev, new_labels_all_dev, true_labels_all_dev, new_start_pos_all_dev = [], [], [], []\n",
        "\n",
        "label_indices_sent_cc = []\n",
        "tokens_sent_cc = []\n",
        "for cc in range(len(X_dev_cc)):\n",
        "  y_pred_dev = crf.predict(X_dev_cc[cc])\n",
        "  y_dev_true = y_dev_cc[cc]\n",
        "\n",
        "  new_tokens, new_labels, true_labels, new_start_pos = [], [], [], []\n",
        "  new_tokens, new_labels, true_labels, new_start_pos = tokens_to_words(token_dev_cc[cc], \n",
        "                                        y_pred_dev, y_dev_true, start_char_dev_cc[cc])\n",
        "  new_tokens_cc.append(new_tokens)\n",
        "  new_labels_cc.append(new_labels)\n",
        "  true_labels_cc.append(true_labels)\n",
        "  new_start_pos_cc.append(new_start_pos)\n",
        "\n",
        "  new_tokens_all_dev.extend(new_tokens)\n",
        "  new_labels_all_dev.extend(new_labels)\n",
        "  true_labels_all_dev.extend(true_labels)\n",
        "  new_start_pos_all_dev.extend(new_start_pos)\n",
        "\n",
        "report_dev_glob = flat_classification_report(y_true = true_labels_all_dev, y_pred = new_labels_all_dev, labels = labels)\n",
        "print(report_dev_glob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhTXfZSpiS0r",
        "colab_type": "text"
      },
      "source": [
        "**Predictions over development set 2**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWnzOZyDiYAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f1e63483-7b2f-4c27-eda3-595c0c76ff37"
      },
      "source": [
        "#Predicting on the development set.\n",
        "y_pred_dev2 = crf.predict(X_dev2)\n",
        "\n",
        "f1_score_crf_dev = flat_f1_score(y_dev2, y_pred_dev2, average = 'micro', labels = labels)\n",
        "precision_crf_dev = flat_precision_score(y_dev2, y_pred_dev2, average = 'micro', labels = labels)\n",
        "recall_crf_dev = flat_recall_score(y_dev2, y_pred_dev2, average = 'micro', labels = labels)\n",
        "\n",
        "print(f1_score_crf_dev)\n",
        "print(precision_crf_dev)\n",
        "print(recall_crf_dev)\n",
        "\n",
        "report_dev2 = flat_classification_report(y_dev2, y_pred_dev2, labels)\n",
        "print(report_dev2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7696570834776584\n",
            "0.8181148748159057\n",
            "0.7266187050359713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-MOR       0.84      0.77      0.81      1277\n",
            "       I-MOR       0.79      0.63      0.70      2185\n",
            "       E-MOR       0.75      0.67      0.71      1276\n",
            "       S-MOR       0.89      0.89      0.89      1375\n",
            "       V-MOR       0.00      0.00      0.00         3\n",
            "\n",
            "   micro avg       0.82      0.73      0.77      6116\n",
            "   macro avg       0.65      0.59      0.62      6116\n",
            "weighted avg       0.81      0.73      0.77      6116\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu-1Zinwdrhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tokens_cc, new_labels_cc, true_labels_cc, new_start_pos_cc = [], [], [], []\n",
        "new_tokens_all_dev2, new_labels_all_dev2, true_labels_all_dev2, new_start_pos_all_dev2 = [], [], [], []\n",
        "\n",
        "label_indices_sent_cc = []\n",
        "tokens_sent_cc = []\n",
        "for cc in range(len(X_dev_cc2)):\n",
        "  y_pred_dev = crf.predict(X_dev_cc2[cc])\n",
        "  y_dev_true = y_dev_cc2[cc]\n",
        "\n",
        "  new_tokens, new_labels, true_labels, new_start_pos = [], [], [], []\n",
        "  new_tokens, new_labels, true_labels, new_start_pos = tokens_to_words(token_dev_cc[cc], \n",
        "                                        y_pred_dev, y_dev_true, start_char_dev_cc[cc])\n",
        "  new_tokens_cc.append(new_tokens)\n",
        "  new_labels_cc.append(new_labels)\n",
        "  true_labels_cc.append(true_labels)\n",
        "  new_start_pos_cc.append(new_start_pos)\n",
        "\n",
        "  new_tokens_all_dev2.extend(new_tokens)\n",
        "  new_labels_all_dev2.extend(new_labels)\n",
        "  true_labels_all_dev2.extend(true_labels)\n",
        "  new_start_pos_all_dev2.extend(new_start_pos)\n",
        "\n",
        "report_dev_glob = flat_classification_report(y_true = true_labels_all_dev2, y_pred = new_labels_all_dev2, labels = labels)\n",
        "print(report_dev_glob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mN5DYWZ0uh",
        "colab_type": "text"
      },
      "source": [
        "##### **Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Or1WpDk3xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_matrix(actual, predicted):\n",
        "    #classes       = np.unique(np.concatenate((actual,predicted)))\n",
        "    classes = ['B-MOR', 'I-MOR', 'E-MOR', 'S-MOR', 'V-MOR', 'O']\n",
        "    confusion_mtx = np.empty((len(classes),len(classes)),dtype=np.int)\n",
        "    for i,a in enumerate(classes):\n",
        "        for j,p in enumerate(classes):\n",
        "            value = sum([sum([np.where((actual[sent][word]==a)*(predicted[sent][word]==p))[0].shape[0] \n",
        "                              for word in range(len(actual[sent]))]) for sent in range(len(actual))])\n",
        "            #confusion_mtx[i,j] = sum([np.where((actual[sent]==a)*(predicted[sent]==p))[0].shape[0] for sent in range(len(actual))])\n",
        "            confusion_mtx[i,j] = value\n",
        "    return confusion_mtx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1vgH_4xovbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code to extract METRICS FOR ENTITY AND NON-ENTITY from the confusion matrix\n",
        "\n",
        "def metrics_from_cm(cm,labels):\n",
        "  TP = [[v for v in value[0:len(labels)]] for value in cm[0:len(labels)]]\n",
        "  print(TP)\n",
        "  TP = np.array(TP)\n",
        "  TP = sum(sum(TP))\n",
        "\n",
        "  FN = [value[-1] for value in cm[0:len(labels)]] # last column is O\n",
        "  print(FN)\n",
        "  FN = np.array(FN) \n",
        "  FN = sum(FN)\n",
        "\n",
        "  FP = cm[len(labels)][0:len(labels)] # last column is O\n",
        "  print(FP)\n",
        "  FP = sum(FP)\n",
        "\n",
        "  TN = cm[len(labels)][len(labels)] # last column is O\n",
        "  print(TN)\n",
        "\n",
        "  return TP, FN, FP, TN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rUYozEOe-ac",
        "colab_type": "text"
      },
      "source": [
        "**Train set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANw7GPuAfE66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "894d3653-33e1-4f2c-b525-2d82283e8f7d"
      },
      "source": [
        "# not done by clinical case\n",
        "actual    = np.array(y_valid)\n",
        "predicted = np.array(y_pred)\n",
        "confusion_matrix_train = confusion_matrix(actual,predicted)\n",
        "\n",
        "df = pd.DataFrame(confusion_matrix_train, columns = ['B-MOR', 'I-MOR','E-MOR','S-MOR','V-MOR','O'], index = ['B-MOR', 'I-MOR','E-MOR','S-MOR','V-MOR','O'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B-MOR</th>\n",
              "      <th>I-MOR</th>\n",
              "      <th>E-MOR</th>\n",
              "      <th>S-MOR</th>\n",
              "      <th>V-MOR</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-MOR</th>\n",
              "      <td>459</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MOR</th>\n",
              "      <td>9</td>\n",
              "      <td>633</td>\n",
              "      <td>41</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E-MOR</th>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>417</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S-MOR</th>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>598</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V-MOR</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>44</td>\n",
              "      <td>152</td>\n",
              "      <td>62</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>87627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       B-MOR  I-MOR  E-MOR  S-MOR  V-MOR      O\n",
              "B-MOR    459      9      0     43      0    119\n",
              "I-MOR      9    633     41      5      0    344\n",
              "E-MOR      0     28    417     19      0    165\n",
              "S-MOR     16      2      6    598      0     36\n",
              "V-MOR      0      0      0      1      0      0\n",
              "O         44    152     62     10      0  87627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nX_c4Kmn3Yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f99d929a-5077-46d7-b4be-a3c488a696b2"
      },
      "source": [
        "TP, FN, FP, TN = metrics_from_cm(confusion_matrix_train,labels)\n",
        "print(TP)\n",
        "print(FN)\n",
        "print(FP)\n",
        "print(TN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[459, 9, 0, 43, 0], [9, 633, 41, 5, 0], [0, 28, 417, 19, 0], [16, 2, 6, 598, 0], [0, 0, 0, 1, 0]]\n",
            "[119, 344, 165, 36, 0]\n",
            "[ 44 152  62  10   0]\n",
            "87627\n",
            "2286\n",
            "664\n",
            "268\n",
            "87627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k22_gc1be7su",
        "colab_type": "text"
      },
      "source": [
        "**Development set 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7jd1pfBqkPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8a8558ce-3a6c-46de-cbb9-91ba01620c4c"
      },
      "source": [
        "# confusion matrix computed over all the clinical cases \n",
        "\n",
        "actual    = np.array(true_labels_all_dev)\n",
        "predicted = np.array(new_labels_all_dev)\n",
        "cm = confusion_matrix(actual,predicted)\n",
        "\n",
        "df = pd.DataFrame(cm, columns = ['B-MOR', 'I-MOR','E-MOR','S-MOR','V-MOR','O'], index = ['B-MOR', 'I-MOR','E-MOR','S-MOR','V-MOR','O'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B-MOR</th>\n",
              "      <th>I-MOR</th>\n",
              "      <th>E-MOR</th>\n",
              "      <th>S-MOR</th>\n",
              "      <th>V-MOR</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-MOR</th>\n",
              "      <td>1140</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>97</td>\n",
              "      <td>0</td>\n",
              "      <td>372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MOR</th>\n",
              "      <td>24</td>\n",
              "      <td>1458</td>\n",
              "      <td>130</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E-MOR</th>\n",
              "      <td>1</td>\n",
              "      <td>82</td>\n",
              "      <td>987</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S-MOR</th>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>1458</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V-MOR</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>138</td>\n",
              "      <td>229</td>\n",
              "      <td>173</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>217272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       B-MOR  I-MOR  E-MOR  S-MOR  V-MOR       O\n",
              "B-MOR   1140     24      6     97      0     372\n",
              "I-MOR     24   1458    130     10      6     951\n",
              "E-MOR      1     82    987     39      3     522\n",
              "S-MOR     39      2     27   1458      0     163\n",
              "V-MOR      4      7      4      3      0       0\n",
              "O        138    229    173     33      0  217272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBSHrMLzp61v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8aa05fb7-759a-4b04-bd23-5b439708e813"
      },
      "source": [
        "TP, FN, FP, TN = metrics_from_cm(cm,labels)\n",
        "print(TP)\n",
        "print(FN)\n",
        "print(FP)\n",
        "print(TN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1140, 24, 6, 97, 0], [24, 1458, 130, 10, 6], [1, 82, 987, 39, 3], [39, 2, 27, 1458, 0], [4, 7, 4, 3, 0]]\n",
            "[372, 951, 522, 163, 0]\n",
            "[138 229 173  33   0]\n",
            "217272\n",
            "5551\n",
            "2008\n",
            "573\n",
            "217272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUL5NTtUilsi",
        "colab_type": "text"
      },
      "source": [
        "**Development set 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETY_kt-tiwSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4c813f0d-f59f-4315-f45f-9a81785551c2"
      },
      "source": [
        "# confusion matrix computed over all the clinical cases \n",
        "\n",
        "actual    = np.array(true_labels_all_dev2)\n",
        "predicted = np.array(new_labels_all_dev2)\n",
        "cm2 = confusion_matrix(actual,predicted)\n",
        "\n",
        "df = pd.DataFrame(cm2, columns = ['B-MOR', 'I-MOR','E-MOR','S-MOR','V-MOR','O'], index = ['B-MOR', 'I-MOR','E-MOR','S-MOR','V-MOR','O'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B-MOR</th>\n",
              "      <th>I-MOR</th>\n",
              "      <th>E-MOR</th>\n",
              "      <th>S-MOR</th>\n",
              "      <th>V-MOR</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-MOR</th>\n",
              "      <td>983</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MOR</th>\n",
              "      <td>17</td>\n",
              "      <td>1383</td>\n",
              "      <td>93</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E-MOR</th>\n",
              "      <td>2</td>\n",
              "      <td>65</td>\n",
              "      <td>859</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S-MOR</th>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>1219</td>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V-MOR</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>127</td>\n",
              "      <td>277</td>\n",
              "      <td>170</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>176467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       B-MOR  I-MOR  E-MOR  S-MOR  V-MOR       O\n",
              "B-MOR    983     16      4     86      0     188\n",
              "I-MOR     17   1383     93      6      0     686\n",
              "E-MOR      2     65    859     35      0     315\n",
              "S-MOR     36      4     19   1219      0      97\n",
              "V-MOR      0      2      1      0      0       0\n",
              "O        127    277    170     28      0  176467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myhpjeHNi4Ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "502b0a8a-bd36-4778-9a03-8141a4714326"
      },
      "source": [
        "TP, FN, FP, TN = metrics_from_cm(cm2,labels)\n",
        "print(TP)\n",
        "print(FN)\n",
        "print(FP)\n",
        "print(TN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[983, 16, 4, 86, 0], [17, 1383, 93, 6, 0], [2, 65, 859, 35, 0], [36, 4, 19, 1219, 0], [0, 2, 1, 0, 0]]\n",
            "[188, 686, 315, 97, 0]\n",
            "[127 277 170  28   0]\n",
            "176467\n",
            "4830\n",
            "1286\n",
            "602\n",
            "176467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soI3QqsPqgHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uau3zx4dqG7b",
        "colab_type": "text"
      },
      "source": [
        "### **Final CRF model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvG_lW-ZxjzP",
        "colab_type": "text"
      },
      "source": [
        "##### **Costruct complete dataset**\n",
        "by merging train and development datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoAdQ9Ypx0p6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9bbead95-b050-4f17-c9fc-a9b9560c08ae"
      },
      "source": [
        "print(sentences_dev[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('anamnesis', 'NOUN', 'O', 0), ('\\n', 'SPACE', 'O', 9), ('varon', 'PROPN', 'O', 10), ('de', 'ADP', 'O', 16), ('74', 'NUM', 'O', 19), ('anos', 'NOUN', 'O', 22), (',', 'PUNCT', 'O', 26), ('exfumador', 'NOUN', 'O', 28), ('desde', 'ADP', 'O', 38), ('hace', 'AUX', 'O', 44), ('15', 'NUM', 'O', 49), ('anos', 'NOUN', 'O', 52), (',', 'PUNCT', 'O', 56), ('con', 'ADP', 'O', 58), ('unico', 'ADJ', 'O', 62), ('antecedente', 'NOUN', 'O', 68), ('de', 'ADP', 'O', 80), ('hipertension', 'NOUN', 'O', 83), (',', 'PUNCT', 'O', 95), ('dislipemia', 'NOUN', 'O', 97), ('y', 'CCONJ', 'O', 108), ('apendicectomizado', 'ADJ', 'O', 110), (';', 'PUNCT', 'O', 127), ('se', 'PRON', 'O', 129), ('diagnostica', 'VERB', 'O', 132), ('en', 'ADP', 'O', 144), ('marzo', 'INTJ', 'O', 147), ('de', 'ADP', 'O', 153), ('2013', 'NUM', 'O', 156), ('de', 'ADP', 'O', 161), ('carcinoma', 'INTJ', 'B-MOR', 164), ('de', 'ADP', 'I-MOR', 174), ('celulas', 'NOUN', 'I-MOR', 177), ('transicionales', 'ADJ', 'I-MOR', 185), ('de', 'ADP', 'I-MOR', 200), ('vejiga', 'PROPN', 'I-MOR', 203), ('e-iv', 'PROPN', 'I-MOR', 210), ('(', 'PUNCT', 'E-MOR', 215), ('pulmonares', 'ADJ', 'O', 216), ('y', 'CCONJ', 'O', 227), ('oseas', 'ADJ', 'O', 229), (')', 'PUNCT', 'O', 234), ('.', 'PUNCT', 'O', 235)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqxHsxP4xZgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e9d6573a-915e-4b8c-8cef-8afa47434e9e"
      },
      "source": [
        "# CONSTRUCT COMPLETE DATASET\n",
        "\n",
        "print(\"Number of sentences in training dataset 1: %d\" %len(sentences_train))\n",
        "print(\"Number of sentences in development dataset 1: %d\" %len(sentences_dev))\n",
        "print(\"Number of sentences in development dataset 2: %d\" %len(sentences_dev2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in training dataset 1: 19502\n",
            "Number of sentences in development dataset 1: 9546\n",
            "Number of sentences in development dataset 2: 8682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOpvOcf7xxZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_complete = sentences_train.copy()\n",
        "sentences_complete.extend(sentences_dev)\n",
        "sentences_complete.extend(sentences_dev2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZUz6Teuxy7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d2e3265f-c937-4f37-e398-da1597d9f4a2"
      },
      "source": [
        "print(\"Number of sentences in training dataset 1: %d\" %len(sentences_train))\n",
        "print(\"Number of sentences in development dataset 1: %d\" %len(sentences_dev))\n",
        "print(\"Number of sentences in development dataset 2: %d\" %len(sentences_dev2))\n",
        "print(\"Number of sentences in combined dataset: %d\" %len(sentences_complete))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in training dataset 1: 19502\n",
            "Number of sentences in development dataset 1: 9546\n",
            "Number of sentences in development dataset 2: 8682\n",
            "Number of sentences in combined dataset: 37730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSNxxsDWWqTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f15ab959-f510-415a-9587-f6d140f675e9"
      },
      "source": [
        "sentences_complete[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('anamnesis', 'NOUN', 'O', 0),\n",
              " ('\\n', 'SPACE', 'O', 9),\n",
              " ('mujer', 'NOUN', 'O', 10),\n",
              " ('de', 'ADP', 'O', 16),\n",
              " ('67', 'NUM', 'O', 19),\n",
              " ('anos', 'NOUN', 'O', 22),\n",
              " ('con', 'ADP', 'O', 27),\n",
              " ('antecedentes', 'NOUN', 'O', 31),\n",
              " ('personales', 'ADJ', 'O', 44),\n",
              " ('de', 'ADP', 'O', 55),\n",
              " ('hipotiroidismo', 'NOUN', 'O', 58),\n",
              " ('en', 'ADP', 'O', 73),\n",
              " ('tratamiento', 'NOUN', 'O', 76),\n",
              " ('con', 'ADP', 'O', 88),\n",
              " ('levotiroxina', 'NOUN', 'O', 92),\n",
              " ('y', 'CCONJ', 'O', 105),\n",
              " ('fumadora', 'ADJ', 'O', 107),\n",
              " ('activa', 'ADJ', 'O', 116),\n",
              " ('de', 'ADP', 'O', 123),\n",
              " ('12.5', 'NUM', 'O', 126),\n",
              " ('paquetes', 'NOUN', 'O', 131),\n",
              " ('/', 'PUNCT', 'O', 139),\n",
              " ('ano', 'NOUN', 'O', 140),\n",
              " ('.', 'PUNCT', 'O', 143)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWR8RXo4zd2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_complete = [[(preprocess_word(w[0]),w[1],w[2],w[3]) for w in s] for s in sentences_complete]\n",
        "sentences_test_by_cc = [[[(preprocess_word(w[0]),w[1],w[2]) for w in s] for s in cc] for cc in sentences_test_by_cc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz-Jg7DCYgoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6ba9295c-d54e-4d19-809e-eb099bb022c2"
      },
      "source": [
        "print(sentences_test_by_cc[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('anamnesis', 'NOUN', 'O', 0), ('\\n', 'SPACE', 'O', 9), ('se', 'PRON', 'O', 10), ('trata', 'VERB', 'O', 13), ('de', 'ADP', 'O', 19), ('un', 'DET', 'O', 22), ('paciente', 'NOUN', 'O', 25), ('de', 'ADP', 'O', 34), ('67', 'NUM', 'O', 37), ('anos', 'NOUN', 'O', 40), ('en', 'ADP', 'O', 45), ('el', 'DET', 'O', 48), ('momento', 'NOUN', 'O', 51), ('del', 'ADP', 'O', 59), ('diagnostico', 'NOUN', 'O', 63), (',', 'PUNCT', 'O', 74), ('con', 'ADP', 'O', 76), ('antecedentes', 'NOUN', 'O', 80), ('personales', 'ADJ', 'O', 93), ('a', 'ADP', 'O', 104), ('destacar', 'VERB', 'O', 106), ('de', 'ADP', 'O', 115), ('hipercolesterolemia', 'NOUN', 'O', 118), ('en', 'ADP', 'O', 138), ('tratamiento', 'NOUN', 'O', 141), ('con', 'ADP', 'O', 153), ('estatina', 'NOUN', 'O', 157), ('y', 'CCONJ', 'O', 166), ('alteracion', 'NOUN', 'O', 168), ('basal', 'ADJ', 'O', 179), ('de', 'ADP', 'O', 185), ('la', 'DET', 'O', 188), ('glucemia', 'NOUN', 'O', 191), ('en', 'ADP', 'O', 200), ('controles', 'NOUN', 'O', 203), (',', 'PUNCT', 'O', 212), ('exfumador', 'NOUN', 'O', 214), ('hace', 'AUX', 'O', 224), ('cinco', 'NUM', 'O', 229), ('anos', 'NOUN', 'O', 235), ('de', 'ADP', 'O', 240), ('24', 'NUM', 'O', 243), ('paquetes-ano', 'PROPN', 'O', 246), ('.', 'PUNCT', 'O', 258)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmWFU0Ghx6C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN SET formed by the complete dataset\n",
        "X_train = [sent2features(s) for s in sentences_complete] # function called over every sentence in sentences\n",
        "y_train = [sent2labels(s) for s in sentences_complete]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFf1SPwIy0IJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "14e3f1e7-8a4f-4572-fc2e-7037ece953a0"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'bias': 1.0, 'word.lower()': 'anamnesis', 'word[-3:]': 'sis', 'word[-2:]': 'is', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', 'BOS': True, '+1:word.lower()': '\\n', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'SPACE', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': '\\n', 'word[-3:]': '\\n', 'word[-2:]': '\\n', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'SPACE', 'postag[:2]': 'SP', '-1:word.lower()': 'anamnesis', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': 'mujer', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'mujer', 'word[-3:]': 'jer', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': '\\n', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'SPACE', '-1:postag[:2]': 'SP', '+1:word.lower()': 'de', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', '-1:word.lower()': 'mujer', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': '67', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NUM', '+1:postag[:2]': 'NU'}, {'bias': 1.0, 'word.lower()': '67', 'word[-3:]': '67', 'word[-2:]': '67', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': True, 'postag': 'NUM', 'postag[:2]': 'NU', '-1:word.lower()': 'de', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '+1:word.lower()': 'anos', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'anos', 'word[-3:]': 'nos', 'word[-2:]': 'os', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': '67', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NUM', '-1:postag[:2]': 'NU', '+1:word.lower()': 'con', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'con', 'word[-3:]': 'con', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', '-1:word.lower()': 'anos', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': 'antecedentes', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'antecedentes', 'word[-3:]': 'tes', 'word[-2:]': 'es', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': 'con', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '+1:word.lower()': 'personales', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADJ', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'personales', 'word[-3:]': 'les', 'word[-2:]': 'es', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADJ', 'postag[:2]': 'AD', '-1:word.lower()': 'antecedentes', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': 'de', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', '-1:word.lower()': 'personales', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADJ', '-1:postag[:2]': 'AD', '+1:word.lower()': 'hipotiroidismo', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'hipotiroidismo', 'word[-3:]': 'smo', 'word[-2:]': 'mo', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': 'de', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '+1:word.lower()': 'en', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'en', 'word[-3:]': 'en', 'word[-2:]': 'en', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', '-1:word.lower()': 'hipotiroidismo', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': 'tratamiento', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'tratamiento', 'word[-3:]': 'nto', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': 'en', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '+1:word.lower()': 'con', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'con', 'word[-3:]': 'con', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', '-1:word.lower()': 'tratamiento', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': 'levotiroxina', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'levotiroxina', 'word[-3:]': 'ina', 'word[-2:]': 'na', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': 'con', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '+1:word.lower()': 'y', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'CCONJ', '+1:postag[:2]': 'CC'}, {'bias': 1.0, 'word.lower()': 'y', 'word[-3:]': 'y', 'word[-2:]': 'y', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'CCONJ', 'postag[:2]': 'CC', '-1:word.lower()': 'levotiroxina', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': 'fumadora', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADJ', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'fumadora', 'word[-3:]': 'ora', 'word[-2:]': 'ra', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADJ', 'postag[:2]': 'AD', '-1:word.lower()': 'y', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'CCONJ', '-1:postag[:2]': 'CC', '+1:word.lower()': 'activa', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADJ', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'activa', 'word[-3:]': 'iva', 'word[-2:]': 'va', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADJ', 'postag[:2]': 'AD', '-1:word.lower()': 'fumadora', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADJ', '-1:postag[:2]': 'AD', '+1:word.lower()': 'de', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD'}, {'bias': 1.0, 'word.lower()': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', '-1:word.lower()': 'activa', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADJ', '-1:postag[:2]': 'AD', '+1:word.lower()': '12.5', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NUM', '+1:postag[:2]': 'NU'}, {'bias': 1.0, 'word.lower()': '12.5', 'word[-3:]': '2.5', 'word[-2:]': '.5', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NUM', 'postag[:2]': 'NU', '-1:word.lower()': 'de', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '+1:word.lower()': 'paquetes', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'paquetes', 'word[-3:]': 'tes', 'word[-2:]': 'es', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': '12.5', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NUM', '-1:postag[:2]': 'NU', '+1:word.lower()': '/', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'PUNCT', '+1:postag[:2]': 'PU'}, {'bias': 1.0, 'word.lower()': '/', 'word[-3:]': '/', 'word[-2:]': '/', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'PUNCT', 'postag[:2]': 'PU', '-1:word.lower()': 'paquetes', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', '+1:word.lower()': 'ano', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NOUN', '+1:postag[:2]': 'NO'}, {'bias': 1.0, 'word.lower()': 'ano', 'word[-3:]': 'ano', 'word[-2:]': 'no', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NOUN', 'postag[:2]': 'NO', '-1:word.lower()': '/', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'PUNCT', '-1:postag[:2]': 'PU', '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'PUNCT', '+1:postag[:2]': 'PU'}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'PUNCT', 'postag[:2]': 'PU', '-1:word.lower()': 'ano', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NOUN', '-1:postag[:2]': 'NO', 'EOS': True}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u9z-qyIZno7",
        "colab_type": "text"
      },
      "source": [
        "##### **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPajcKOZqKne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crf = CRF(algorithm = 'lbfgs',\n",
        "         c1 = 0.1,\n",
        "         c2 = 0.1,\n",
        "         max_iterations = 100,\n",
        "         all_possible_transitions = False)\n",
        "\n",
        "crf.fit(X_train, y_train)\n",
        "\n",
        "# labels used in the classification report\n",
        "labels = ['B-MOR', 'I-MOR', 'E-MOR', 'S-MOR', 'V-MOR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urWf2Wj11lxQ",
        "colab_type": "text"
      },
      "source": [
        "##### **Predictions over the test and background set**\n",
        "\n",
        "The predictions are obtained over each clinical case independently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWzQvs418eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_words_test(tokens_sent,label_sent, start_char_pos):\n",
        "  new_tok, new_lab, new_start_pos = [], [], []\n",
        "\n",
        "  for tokens, labels, start_chars in zip(tokens_sent, label_sent, start_char_pos):\n",
        "    new_tok_aux, new_lab_aux, new_start_pos_aux = [], [], []\n",
        "    for token, label, start_char_i in zip(tokens, labels,start_chars):\n",
        "      if token != \"PAD\":\n",
        "        new_tok_aux.append(token)\n",
        "        new_lab_aux.append(label)\n",
        "        new_start_pos_aux.append(start_char_i)\n",
        "\n",
        "    new_lab.append(new_lab_aux)\n",
        "    new_tok.append(new_tok_aux)\n",
        "    new_start_pos.append(new_start_pos_aux)\n",
        "\n",
        "  return new_tok, new_lab, new_start_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYTyXEgJ1-Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tokens_cc, new_labels_cc, new_start_pos_cc = [], [], []\n",
        "new_tokens_all, new_labels_all, new_start_pos_all = [], [], []\n",
        "\n",
        "for cc in range(len(X_test_cc)):\n",
        "  y_pred_test = crf.predict(X_test_cc[cc])\n",
        "\n",
        "  new_tokens, new_labels, new_start_pos = [], [], []\n",
        "  new_tokens, new_labels, new_start_pos = tokens_to_words_test(token_test_cc[cc], \n",
        "                                        y_pred_test, start_char_test_cc[cc])\n",
        "  new_tokens_cc.append(new_tokens)\n",
        "  new_labels_cc.append(new_labels)\n",
        "  new_start_pos_cc.append(new_start_pos)\n",
        "\n",
        "  new_tokens_all.extend(new_tokens)\n",
        "  new_labels_all.extend(new_labels)\n",
        "  new_start_pos_all.extend(new_start_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTW2qCgG4igx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9119d5dc-6709-4421-f78d-b3fd16260152"
      },
      "source": [
        "len(new_tokens_cc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES_lDUcs2ACj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle as pkl\n",
        "\n",
        "with open(path+'results_CRF/predictions/new_tokens_cc', 'wb') as file: \n",
        "  pkl.dump(new_tokens_cc, file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_CRF/predictions/new_labels_cc', 'wb') as file: \n",
        "  pkl.dump(new_labels_cc, file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_CRF/predictions/new_start_pos_cc', 'wb') as file: \n",
        "  pkl.dump(new_start_pos_cc, file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}