{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "last_step_cantemist_TEST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IQJM92k5yyLV",
        "tagsZfDrd1lM",
        "NFAK2KhG6Loe",
        "ITlKIwJawjYC",
        "tOHZ6_oxwcyt",
        "RF8h1VBZhFAh",
        "ca9CYcsOQfT8",
        "1Q0r_1nuwnSv",
        "OEj98kGMmWcN",
        "r1XHE1u_W4VA",
        "FemoAmPM85uQ",
        "jPsE8WxrlSvj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa8LE4iUs5op",
        "colab_type": "text"
      },
      "source": [
        "# **Create Annotation Files**\n",
        "\n",
        "## **Author:** Gema De Vargas Romero\n",
        "\n",
        "## **Master Thesis:** \"Development of a Named Entity Recognition System to automatically assign tumor morphology entity mentions to health-related documents in Spanish.\" \n",
        "\n",
        "The aim of this notebook is to construct the annotation files of the predictions. For this purpose, for every machine learning method employed, it will:\n",
        "\n",
        "1. take the predicted labels for each clinical case \n",
        "2. construct the corresponding BRAT annotation \n",
        "3. Store the annotations in as many files as clinical cases in the test dataset using the same name as the txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05N_SwgGTL6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "25144d65-15af-4fad-f388-6e9254748fab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "path='drive/My Drive/Ejemplos NER - TFM/'\n",
        "!ls 'drive/My Drive/Ejemplos NER - TFM/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            " bert\n",
            " data\n",
            " dev_set\n",
            " dev_set2\n",
            "'Dictionary based NER (spacy).ipynb'\n",
            "'Ehealth_Dictionary based NER (spacy).ipynb'\n",
            " last_step_cantemist.ipynb\n",
            " last_step_cantemist_TEST.ipynb\n",
            " NER_by_BERT_Cantemist_BIOESV.ipynb\n",
            " NER_by_BERT_Cantemist_Competicion.ipynb\n",
            " NER_by_BERT_Cantemist.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist_BIOESV_2.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist_BIOESV.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist_Competicion.ipynb\n",
            " NER_by_BI_LSTM_CRF_Cantemist.ipynb\n",
            " NER_by_CRF_Cantemist_Competicion.ipynb\n",
            " NER_by_CRF_Cantemist.ipynb\n",
            " NER_by_CRF_Ehealth.ipynb\n",
            " NER_by_CRF.ipynb\n",
            " Preprocessing_NER_Cantemist.ipynb\n",
            " resources\n",
            " results_bert\n",
            " results_bert2\n",
            " results_BILSTM_ap1\n",
            " results_BILSTM_ap2\n",
            " results_BILSTM_ap3\n",
            " results_CRF\n",
            " sample_set\n",
            " Scielo+Wiki_skipgram_cased.bin\n",
            " Scielo+Wiki_skipgram_cased.vec\n",
            " test-background-set-to-publish\n",
            " train_set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQJM92k5yyLV",
        "colab_type": "text"
      },
      "source": [
        "### **Load libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs2wGon2y3AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d326ab77-bf55-4a08-b913-c1efc0d92dba"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "# Library spacy\n",
        "!pip install -U spacy \n",
        "#!python -m spacy validate\n",
        "!python -m spacy download es_core_news_lg\n",
        "import spacy\n",
        "\n",
        "# nlp = spacy.load(\"es\") # no longer works with updated version of spacy 2.3.1\n",
        "import es_core_news_lg\n",
        "nlp = es_core_news_lg.load()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/b5/c7a92c7ce5d4b353b70b4b5b4385687206c8b230ddfe08746ab0fd310a3a/spacy-2.3.2-cp36-cp36m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Collecting thinc==7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 60.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.2 thinc-7.4.1\n",
            "Collecting es_core_news_lg==2.3.1\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-2.3.1/es_core_news_lg-2.3.1.tar.gz (573.1MB)\n",
            "\u001b[K     |████████████████████████████████| 573.1MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from es_core_news_lg==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (0.7.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (49.2.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.1.0)\n",
            "Building wheels for collected packages: es-core-news-lg\n",
            "  Building wheel for es-core-news-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-lg: filename=es_core_news_lg-2.3.1-cp36-none-any.whl size=573139081 sha256=38e6f0a8a7e5ef4f78ad92a55c6b21fb9e94fc58dcd6b93356d1b9ef0be73f90\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6mlc5xl5/wheels/48/59/33/558e7f48e924c6cac0cbd3679ee7c84f5ae02964c335232e5a\n",
            "Successfully built es-core-news-lg\n",
            "Installing collected packages: es-core-news-lg\n",
            "Successfully installed es-core-news-lg-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tagsZfDrd1lM"
      },
      "source": [
        "### **Read the names of the files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzNOb-C4UKIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read names of the files\n",
        "with open(path+'data/files_txt_test', 'rb') as file: \n",
        "  files_txt_test = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBhpuQ3Nk0VW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "For simplicity, the prediction files of each method are being stored in arrays with the same name. The reason for this overlap is to avoid repeating the code to construct the annotation files as many times as methods. \n",
        "\n",
        "This way, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFAK2KhG6Loe",
        "colab_type": "text"
      },
      "source": [
        "### **Read CRF prediction files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgM0oqjz6SyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path+'results_CRF/predictions/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_CRF/predictions/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_CRF/predictions/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJZrvJhX6Z-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09cd7fa8-570f-4609-a9b2-b7bc7388e903"
      },
      "source": [
        "print(\"Number of sentences in complete set: %d\" %len(new_tokens_cc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in complete set: 5232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAdrgeKA6Yyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "11c12afa-b2e5-4216-929f-573cdae98ad3"
      },
      "source": [
        "# Example:\n",
        "for token, label, new_start in zip(new_tokens_cc[0][0], new_labels_cc[0][0], new_start_pos_cc[0][0]):\n",
        "    print(\"{}\\t{}\\t{}\".format(label, token,new_start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\tpaciente\t0\n",
            "O\tmujer\t9\n",
            "O\t,\t14\n",
            "O\t75\t16\n",
            "O\tanos\t19\n",
            "O\tconsulta\t24\n",
            "O\tel\t33\n",
            "O\t4-6-2003\t36\n",
            "O\t,\t44\n",
            "O\trefiriendo\t46\n",
            "O\tcomo\t57\n",
            "O\tantecedentes\t62\n",
            "O\tpersonales\t75\n",
            "O\t:\t85\n",
            "O\talergia\t87\n",
            "O\ta\t95\n",
            "O\tsalicilatos\t97\n",
            "O\t.\t108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITlKIwJawjYC",
        "colab_type": "text"
      },
      "source": [
        "### **Read BILSTM approach 1 prediction files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmXWOBMEwqkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap1/predictions/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap1/predictions/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap1/predictions/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2E1YGoxw2fP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2e0fc36-69d1-4fb1-eb7a-c242bf8a3743"
      },
      "source": [
        "print(\"Number of sentences in complete set: %d\" %len(new_tokens_cc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in complete set: 5232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV_x9fE3wzVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "faeb0d5d-514d-411f-b607-2df0f14250f2"
      },
      "source": [
        "# Example:\n",
        "for token, label, new_start in zip(new_tokens_cc[0][0], new_labels_cc[0][0], new_start_pos_cc[0][0]):\n",
        "    print(\"{}\\t{}\\t{}\".format(label, token,new_start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\tPaciente\t0\n",
            "O\tmujer\t9\n",
            "O\t,\t14\n",
            "O\t75\t16\n",
            "O\taños\t19\n",
            "O\tconsulta\t24\n",
            "O\tel\t33\n",
            "O\t4-6-2003\t36\n",
            "O\t,\t44\n",
            "O\trefiriendo\t46\n",
            "O\tcomo\t57\n",
            "O\tantecedentes\t62\n",
            "O\tpersonales\t75\n",
            "O\t:\t85\n",
            "O\tAlergia\t87\n",
            "O\ta\t95\n",
            "O\tsalicilatos\t97\n",
            "O\t.\t108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHZ6_oxwcyt",
        "colab_type": "text"
      },
      "source": [
        "### **Read BILSTM approach 2 prediction files**\n",
        "\n",
        "NOTE: the predictions of this approach were stored in different foulders bases on the subset of files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzZV2H_IhzUz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "982941e6-e9a7-47ed-a941-ce2ca512cbaf"
      },
      "source": [
        "!ls 'drive/My Drive/Ejemplos NER - TFM/results_BILSTM_ap2/predictions/'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subset1  subset2  subset3  subset4  subset5  subset6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJUKJz61yN-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap2/predictions/subset1/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc1 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset1/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc1 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset1/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc1 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8hfywGulCUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap2/predictions/subset2/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc2 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset2/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc2 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset2/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc2 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTChVpEklxDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap2/predictions/subset3/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc3 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset3/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc3 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset3/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc3 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXogjY6llxcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap2/predictions/subset4/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc4 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset4/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc4 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset4/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc4 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TenFB86plx7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap2/predictions/subset5/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc5 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset5/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc5 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap2/predictions/subset5/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc5 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LK_VVfBlmL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c318d6ce-fcdf-4162-dcc8-83d290772a66"
      },
      "source": [
        "print(\"Number of sentences in subset 1: %d\" %len(new_tokens_cc1))\n",
        "print(\"Number of sentences in subset 2: %d\" %len(new_tokens_cc2))\n",
        "print(\"Number of sentences in subset 3: %d\" %len(new_tokens_cc3))\n",
        "print(\"Number of sentences in subset 4: %d\" %len(new_tokens_cc4))\n",
        "print(\"Number of sentences in subset 5: %d\" %len(new_tokens_cc5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in subset 1: 1000\n",
            "Number of sentences in subset 2: 1000\n",
            "Number of sentences in subset 3: 1000\n",
            "Number of sentences in subset 4: 1000\n",
            "Number of sentences in subset 5: 1232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTJzb9GmmIQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tokens_cc = new_tokens_cc1.copy()\n",
        "new_tokens_cc.extend(new_tokens_cc2)\n",
        "new_tokens_cc.extend(new_tokens_cc3)\n",
        "new_tokens_cc.extend(new_tokens_cc4)\n",
        "new_tokens_cc.extend(new_tokens_cc5)\n",
        "\n",
        "new_labels_cc = new_labels_cc1.copy()\n",
        "new_labels_cc.extend(new_labels_cc2)\n",
        "new_labels_cc.extend(new_labels_cc3)\n",
        "new_labels_cc.extend(new_labels_cc4)\n",
        "new_labels_cc.extend(new_labels_cc5)\n",
        "\n",
        "new_start_pos_cc = new_start_pos_cc1.copy()\n",
        "new_start_pos_cc.extend(new_start_pos_cc2)\n",
        "new_start_pos_cc.extend(new_start_pos_cc3)\n",
        "new_start_pos_cc.extend(new_start_pos_cc4)\n",
        "new_start_pos_cc.extend(new_start_pos_cc5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0X_8iiYlpcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6f17106b-fe45-47a8-9082-ff70951235bb"
      },
      "source": [
        "print(\"Number of sentences in subset 1: %d\" %len(new_tokens_cc1))\n",
        "print(\"Number of sentences in subset 2: %d\" %len(new_tokens_cc2))\n",
        "print(\"Number of sentences in subset 3: %d\" %len(new_tokens_cc3))\n",
        "print(\"Number of sentences in subset 4: %d\" %len(new_tokens_cc4))\n",
        "print(\"Number of sentences in subset 5: %d\" %len(new_tokens_cc5))\n",
        "print(\"Number of sentences in complete set: %d\" %len(new_tokens_cc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in subset 1: 1000\n",
            "Number of sentences in subset 2: 1000\n",
            "Number of sentences in subset 3: 1000\n",
            "Number of sentences in subset 4: 1000\n",
            "Number of sentences in subset 5: 1232\n",
            "Number of sentences in complete set: 5232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nVTXgtEmMh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7a396337-a759-4d90-df9e-e0b48ec8b2a0"
      },
      "source": [
        "# Example:\n",
        "for token, label, new_start in zip(new_tokens_cc[0][0], new_labels_cc[0][0], new_start_pos_cc[0][0]):\n",
        "    print(\"{}\\t{}\\t{}\".format(label, token,new_start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\tPaciente\t0\n",
            "O\tmujer\t9\n",
            "O\t,\t14\n",
            "O\t75\t16\n",
            "O\taños\t19\n",
            "O\tconsulta\t24\n",
            "O\tel\t33\n",
            "O\t4-6-2003\t36\n",
            "O\t,\t44\n",
            "O\trefiriendo\t46\n",
            "O\tcomo\t57\n",
            "O\tantecedentes\t62\n",
            "O\tpersonales\t75\n",
            "O\t:\t85\n",
            "O\tAlergia\t87\n",
            "O\ta\t95\n",
            "O\tsalicilatos\t97\n",
            "O\t.\t108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RF8h1VBZhFAh"
      },
      "source": [
        "### **Read BILSTM approach 3 prediction files**\n",
        "\n",
        "NOTE: the predictions of this approach were stored in different foulders bases on the subset of files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6A9zoxYhFAj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8a47e12-0a57-415a-febb-f611b1ba8299"
      },
      "source": [
        "!ls 'drive/My Drive/Ejemplos NER - TFM/results_BILSTM_ap3/predictions/'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subset1  subset2  subset3  subset4  subset5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h4w8bDnLhFAn",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap3/predictions/subset1/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc1 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset1/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc1 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset1/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc1 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GM2wx6c3hFAp",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap3/predictions/subset2/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc2 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset2/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc2 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset2/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc2 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kuvehJj4hFAr",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap3/predictions/subset3/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc3 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset3/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc3 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset3/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc3 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I6aEQS3MhFAt",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap3/predictions/subset4/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc4 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset4/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc4 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset4/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc4 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Xh0KbdihFAv",
        "colab": {}
      },
      "source": [
        "with open(path+'results_BILSTM_ap3/predictions/subset5/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc5 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset5/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc5 = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_BILSTM_ap3/predictions/subset5/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc5 = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GJ40KRAWhFAx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f68870f7-6e20-40e9-abba-023fd246cc64"
      },
      "source": [
        "print(\"Number of sentences in subset 1: %d\" %len(new_tokens_cc1))\n",
        "print(\"Number of sentences in subset 2: %d\" %len(new_tokens_cc2))\n",
        "print(\"Number of sentences in subset 3: %d\" %len(new_tokens_cc3))\n",
        "print(\"Number of sentences in subset 4: %d\" %len(new_tokens_cc4))\n",
        "print(\"Number of sentences in subset 5: %d\" %len(new_tokens_cc5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in subset 1: 1000\n",
            "Number of sentences in subset 2: 1000\n",
            "Number of sentences in subset 3: 1000\n",
            "Number of sentences in subset 4: 1000\n",
            "Number of sentences in subset 5: 1232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9NkCrjFzhFAz",
        "colab": {}
      },
      "source": [
        "new_tokens_cc = new_tokens_cc1.copy()\n",
        "new_tokens_cc.extend(new_tokens_cc2)\n",
        "new_tokens_cc.extend(new_tokens_cc3)\n",
        "new_tokens_cc.extend(new_tokens_cc4)\n",
        "new_tokens_cc.extend(new_tokens_cc5)\n",
        "\n",
        "new_labels_cc = new_labels_cc1.copy()\n",
        "new_labels_cc.extend(new_labels_cc2)\n",
        "new_labels_cc.extend(new_labels_cc3)\n",
        "new_labels_cc.extend(new_labels_cc4)\n",
        "new_labels_cc.extend(new_labels_cc5)\n",
        "\n",
        "new_start_pos_cc = new_start_pos_cc1.copy()\n",
        "new_start_pos_cc.extend(new_start_pos_cc2)\n",
        "new_start_pos_cc.extend(new_start_pos_cc3)\n",
        "new_start_pos_cc.extend(new_start_pos_cc4)\n",
        "new_start_pos_cc.extend(new_start_pos_cc5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N85SFPBThFA1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "40429c24-d430-4fc7-e39f-16fae708e43e"
      },
      "source": [
        "print(\"Number of sentences in subset 1: %d\" %len(new_tokens_cc1))\n",
        "print(\"Number of sentences in subset 2: %d\" %len(new_tokens_cc2))\n",
        "print(\"Number of sentences in subset 3: %d\" %len(new_tokens_cc3))\n",
        "print(\"Number of sentences in subset 4: %d\" %len(new_tokens_cc4))\n",
        "print(\"Number of sentences in subset 5: %d\" %len(new_tokens_cc5))\n",
        "print(\"Number of sentences in complete set: %d\" %len(new_tokens_cc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in subset 1: 1000\n",
            "Number of sentences in subset 2: 1000\n",
            "Number of sentences in subset 3: 1000\n",
            "Number of sentences in subset 4: 1000\n",
            "Number of sentences in subset 5: 1232\n",
            "Number of sentences in complete set: 5232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1r5fBEAxhFA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "268cf01b-28b5-4a40-9abe-fcf84f0019b7"
      },
      "source": [
        "# Example:\n",
        "for token, label, new_start in zip(new_tokens_cc[0][1], new_labels_cc[0][1], new_start_pos_cc[0][1]):\n",
        "    print(\"{}\\t{}\\t{}\".format(label, token,new_start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\tA\t110\n",
            "O\tlos\t112\n",
            "O\t59\t116\n",
            "O\taños\t119\n",
            "O\tfué\t124\n",
            "O\tdiagnosticada\t128\n",
            "O\tde\t142\n",
            "O\tfiebre\t145\n",
            "O\tde\t152\n",
            "O\tprobable\t155\n",
            "O\tetiología\t164\n",
            "O\tespecífica\t174\n",
            "O\t,\t184\n",
            "O\ttratada\t186\n",
            "O\tcon\t194\n",
            "O\ttuberculostáticos\t198\n",
            "O\t,\t215\n",
            "O\tsegún\t217\n",
            "O\tpauta\t223\n",
            "O\thabitual\t229\n",
            "O\t.\t237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ca9CYcsOQfT8"
      },
      "source": [
        "### **Read BERT prediction files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ck6qNP3oQfUD",
        "colab": {}
      },
      "source": [
        "with open(path+'results_bert2/predictions/new_tokens_cc', 'rb') as file: \n",
        "  new_tokens_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_bert2/predictions/new_labels_cc', 'rb') as file: \n",
        "  new_labels_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'results_bert2/predictions/new_start_pos_cc', 'rb') as file: \n",
        "  new_start_pos_cc = pkl.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f7v54C2eQfUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "783ca992-5502-42f2-90fd-a5f547986fe7"
      },
      "source": [
        "print(\"Number of sentences in complete set: %d\" %len(new_tokens_cc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in complete set: 5232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u1xmhz5_QfUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e4253bea-fab1-4666-a73b-d9f603d0e7a4"
      },
      "source": [
        "# Example:\n",
        "for token, label, new_start in zip(new_tokens_cc[0][0], new_labels_cc[0][0], new_start_pos_cc[0][0]):\n",
        "    print(\"{}\\t{}\\t{}\".format(label, token,new_start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\tPaciente\t0\n",
            "O\tmujer\t9\n",
            "O\t,\t14\n",
            "O\t75\t16\n",
            "O\taños\t19\n",
            "O\tconsulta\t24\n",
            "O\tel\t33\n",
            "O\t4\t36\n",
            "O\t-\t36\n",
            "O\t6\t36\n",
            "O\t-\t36\n",
            "O\t2003\t36\n",
            "O\t,\t44\n",
            "O\trefiriendo\t46\n",
            "O\tcomo\t57\n",
            "O\tantecedentes\t62\n",
            "O\tpersonales\t75\n",
            "O\t:\t85\n",
            "O\tAlergia\t87\n",
            "O\ta\t95\n",
            "O\tsalicilatos\t97\n",
            "O\t.\t108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q0r_1nuwnSv",
        "colab_type": "text"
      },
      "source": [
        "### **Read test files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCG3qPgo420g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST FILES:\n",
        "with open(path+'data/sentences_test', 'rb') as file: \n",
        "  sentences_test = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "with open(path+'data/sentences_test_by_cc', 'rb') as file: \n",
        "  sentences_test_by_cc = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "df_data_test = pd.read_csv(path+'data/df_data_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEj98kGMmWcN",
        "colab_type": "text"
      },
      "source": [
        "## **Results**\n",
        "\n",
        "This code must be executed after reading the prediction files of each method. \n",
        "For example, read CRF prediction files and then execute these cells. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1XHE1u_W4VA",
        "colab_type": "text"
      },
      "source": [
        "### **Construct the results dataframe**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mBxezEpmb_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf8a99bd-b856-453f-9b78-e8f44c00c3a0"
      },
      "source": [
        "print(\"Number of files in the dataset: %d\" %len(new_tokens_cc))\n",
        "\n",
        "file_index = 0\n",
        "sent_index = 0\n",
        "data_words = []\n",
        "\n",
        "for cc in range(len(new_tokens_cc)): # iterate over clinical cases\n",
        "  file_index = file_index + 1\n",
        "\n",
        "  for sent in range(len(new_tokens_cc[cc])): # iterate over sentences of a clinical case\n",
        "    sent_index = sent_index + 1\n",
        "    for word in range(len(new_tokens_cc[cc][sent])):\n",
        "      data_words.append((file_index,sent_index,new_tokens_cc[cc][sent][word], new_start_pos_cc[cc][sent][word], \n",
        "                         new_labels_cc[cc][sent][word]))\n",
        "\n",
        "df_data_results = pd.DataFrame(data_words, columns = [\"File_Index\",\"Sentence_Index\", \"Word\", \"New_Start_Char_position\", \"New_Label\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of files in the dataset: 5232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJLccKBLmwEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c3d5a503-7beb-4631-be55-98039bca283a"
      },
      "source": [
        "df_data_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Index</th>\n",
              "      <th>Sentence_Index</th>\n",
              "      <th>Word</th>\n",
              "      <th>New_Start_Char_position</th>\n",
              "      <th>New_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Paciente</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>mujer</td>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>,</td>\n",
              "      <td>14</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>16</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>años</td>\n",
              "      <td>19</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104646</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>433</td>\n",
              "      <td>6226</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104647</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>U</td>\n",
              "      <td>6230</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104648</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>/</td>\n",
              "      <td>6231</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104649</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>ml</td>\n",
              "      <td>6232</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104650</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>.</td>\n",
              "      <td>6234</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2104651 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         File_Index  Sentence_Index  ... New_Start_Char_position  New_Label\n",
              "0                 1               1  ...                       0          O\n",
              "1                 1               1  ...                       9          O\n",
              "2                 1               1  ...                      14          O\n",
              "3                 1               1  ...                      16          O\n",
              "4                 1               1  ...                      19          O\n",
              "...             ...             ...  ...                     ...        ...\n",
              "2104646        5232           88839  ...                    6226          O\n",
              "2104647        5232           88839  ...                    6230          O\n",
              "2104648        5232           88839  ...                    6231          O\n",
              "2104649        5232           88839  ...                    6232          O\n",
              "2104650        5232           88839  ...                    6234          O\n",
              "\n",
              "[2104651 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a7CImr4nM6E",
        "colab_type": "text"
      },
      "source": [
        "Bert tokenization has produced sentences with either a higher number of words (tokens) or smaller number of words. However, we can trust merging by the new start char position. In fact, the tokens that were not captured by bert tokenization do not have a semantic worth, therefore, it is not crucial for them to merged,since their tag is 'O'.\n",
        "\n",
        "On the other hand, bert tokenizer may have split words that are entities into various. This way, the original word will be merged as many times as subwords. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5-xvDd-W7yF",
        "colab_type": "text"
      },
      "source": [
        "#### **Original dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZnLT3H9W-jA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "3edaee03-883d-4d88-a48f-94e2d9aea658"
      },
      "source": [
        "df_data_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Index</th>\n",
              "      <th>Sentence_Index</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Start_Char_position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Paciente</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>mujer</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>NUM</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>años</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2167543</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>433</td>\n",
              "      <td>NUM</td>\n",
              "      <td>6226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2167544</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>U</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>6230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2167545</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>/</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>6231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2167546</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>ml</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>6232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2167547</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>6234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2167548 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         File_Index  Sentence_Index      Word    POS  Start_Char_position\n",
              "0                 1               1  Paciente  PROPN                    0\n",
              "1                 1               1     mujer   NOUN                    9\n",
              "2                 1               1         ,  PUNCT                   14\n",
              "3                 1               1        75    NUM                   16\n",
              "4                 1               1      años   NOUN                   19\n",
              "...             ...             ...       ...    ...                  ...\n",
              "2167543        5232           88839       433    NUM                 6226\n",
              "2167544        5232           88839         U  PROPN                 6230\n",
              "2167545        5232           88839         /  PUNCT                 6231\n",
              "2167546        5232           88839        ml   NOUN                 6232\n",
              "2167547        5232           88839         .  PUNCT                 6234\n",
              "\n",
              "[2167548 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FemoAmPM85uQ",
        "colab_type": "text"
      },
      "source": [
        "### **Merge the dataframe of the results with the original dataframe**\n",
        "\n",
        "The aim of this operation is to obtain the position of each token in the whole clinical case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg6f6s1goGMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data_results2 = df_data_test.merge(df_data_results[['File_Index','Sentence_Index','Word','New_Start_Char_position','New_Label']],\n",
        "                                      how = 'left', left_on=[\"File_Index\",\"Sentence_Index\", \"Start_Char_position\"], \n",
        "                                      right_on=[\"File_Index\",\"Sentence_Index\",\"New_Start_Char_position\"], suffixes=('','_new'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em1xRSA8o-Tg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "64551ba3-2fc5-4603-eed5-96f68458b554"
      },
      "source": [
        "df_data_results2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Index</th>\n",
              "      <th>Sentence_Index</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Start_Char_position</th>\n",
              "      <th>Word_new</th>\n",
              "      <th>New_Start_Char_position</th>\n",
              "      <th>New_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Paciente</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>0</td>\n",
              "      <td>Paciente</td>\n",
              "      <td>0.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>mujer</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>9</td>\n",
              "      <td>mujer</td>\n",
              "      <td>9.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>14</td>\n",
              "      <td>,</td>\n",
              "      <td>14.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>NUM</td>\n",
              "      <td>16</td>\n",
              "      <td>75</td>\n",
              "      <td>16.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>años</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>19</td>\n",
              "      <td>años</td>\n",
              "      <td>19.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233130</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>433</td>\n",
              "      <td>NUM</td>\n",
              "      <td>6226</td>\n",
              "      <td>433</td>\n",
              "      <td>6226.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233131</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>U</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>6230</td>\n",
              "      <td>U</td>\n",
              "      <td>6230.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233132</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>/</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>6231</td>\n",
              "      <td>/</td>\n",
              "      <td>6231.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233133</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>ml</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>6232</td>\n",
              "      <td>ml</td>\n",
              "      <td>6232.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233134</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>6234</td>\n",
              "      <td>.</td>\n",
              "      <td>6234.0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2233135 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         File_Index  Sentence_Index  ... New_Start_Char_position New_Label\n",
              "0                 1               1  ...                     0.0         O\n",
              "1                 1               1  ...                     9.0         O\n",
              "2                 1               1  ...                    14.0         O\n",
              "3                 1               1  ...                    16.0         O\n",
              "4                 1               1  ...                    19.0         O\n",
              "...             ...             ...  ...                     ...       ...\n",
              "2233130        5232           88839  ...                  6226.0         O\n",
              "2233131        5232           88839  ...                  6230.0         O\n",
              "2233132        5232           88839  ...                  6231.0         O\n",
              "2233133        5232           88839  ...                  6232.0         O\n",
              "2233134        5232           88839  ...                  6234.0         O\n",
              "\n",
              "[2233135 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvZjxe82peuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data_results2_n = df_data_results2.drop_duplicates(['File_Index','Sentence_Index','Start_Char_position'], keep = 'first')\n",
        "df_data_results2_n = df_data_results2_n[['File_Index','Sentence_Index','Word','Start_Char_position','New_Label']]\n",
        "#df_data_results2_n = df_data_results2_n.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXciFSvquwZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "444561ff-8954-4571-ffd6-8c6c9cfda7f7"
      },
      "source": [
        "df_data_results2_n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Index</th>\n",
              "      <th>Sentence_Index</th>\n",
              "      <th>Word</th>\n",
              "      <th>Start_Char_position</th>\n",
              "      <th>New_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Paciente</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>mujer</td>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>,</td>\n",
              "      <td>14</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>16</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>años</td>\n",
              "      <td>19</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233130</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>433</td>\n",
              "      <td>6226</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233131</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>U</td>\n",
              "      <td>6230</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233132</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>/</td>\n",
              "      <td>6231</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233133</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>ml</td>\n",
              "      <td>6232</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233134</th>\n",
              "      <td>5232</td>\n",
              "      <td>88839</td>\n",
              "      <td>.</td>\n",
              "      <td>6234</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2167548 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         File_Index  Sentence_Index      Word  Start_Char_position New_Label\n",
              "0                 1               1  Paciente                    0         O\n",
              "1                 1               1     mujer                    9         O\n",
              "2                 1               1         ,                   14         O\n",
              "3                 1               1        75                   16         O\n",
              "4                 1               1      años                   19         O\n",
              "...             ...             ...       ...                  ...       ...\n",
              "2233130        5232           88839       433                 6226         O\n",
              "2233131        5232           88839         U                 6230         O\n",
              "2233132        5232           88839         /                 6231         O\n",
              "2233133        5232           88839        ml                 6232         O\n",
              "2233134        5232           88839         .                 6234         O\n",
              "\n",
              "[2167548 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfWF1AqTuTiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8d48b610-af65-481e-ba3b-77314c959587"
      },
      "source": [
        "num_BMOR = len(df_data_results2_n[df_data_results2_n['New_Label']=='B-MOR'])\n",
        "num_IMOR = len(df_data_results2_n[df_data_results2_n['New_Label']=='I-MOR'])\n",
        "num_EMOR = len(df_data_results2_n[df_data_results2_n['New_Label']=='E-MOR'])\n",
        "num_SMOR = len(df_data_results2_n[df_data_results2_n['New_Label']=='S-MOR'])\n",
        "num_VMOR = len(df_data_results2_n[df_data_results2_n['New_Label']=='V-MOR'])\n",
        "\n",
        "print(\"Number of B-MOR entities: %d\" %num_BMOR)\n",
        "print(\"Number of I-MOR entities: %d\" %num_IMOR)\n",
        "print(\"Number of E-MOR entities: %d\" %num_EMOR)\n",
        "print(\"Number of S-MOR entities: %d\" %num_SMOR)\n",
        "print(\"Number of V-MOR entities: %d\" %num_VMOR)\n",
        "\n",
        "print(\"\\nTotal number of identified entity words: %d\" %(num_BMOR + num_IMOR + num_EMOR + num_SMOR + num_VMOR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of B-MOR entities: 5297\n",
            "Number of I-MOR entities: 8172\n",
            "Number of E-MOR entities: 5202\n",
            "Number of S-MOR entities: 7628\n",
            "Number of V-MOR entities: 0\n",
            "\n",
            "Total number of identified entity words: 26299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on7T0c7ZU-Ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Number of B-MOR entities: 5840\n",
        "Number of I-MOR entities: 8674\n",
        "Number of E-MOR entities: 5820\n",
        "Number of S-MOR entities: 7616\n",
        "Number of V-MOR entities: 0\n",
        "\n",
        "Total number of identified entity words: 27950"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEZUXenrySAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class sentence(object):\n",
        "    def __init__(self, df):\n",
        "        self.n_sent = 1\n",
        "        self.df = df\n",
        "        self.empty = False\n",
        "        agg = lambda s : [(w, p, l) for w, p, l in zip(s['Word'].values.tolist(),\n",
        "                                                       s['Start_Char_position'].values.tolist(),\n",
        "                                                       s['New_Label'].values.tolist())]\n",
        "        self.grouped = self.df.groupby(\"Sentence_Index\").apply(agg)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "        \n",
        "    def get_text(self):\n",
        "        try:\n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent +=1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnxIWF1-zpzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# by clinical case\n",
        "getter_by_cc = df_data_results2_n.groupby(\"File_Index\").apply(sentence)\n",
        "\n",
        "sentences_by_cc = []\n",
        "\n",
        "for getter_i in getter_by_cc: # iterating over all the files\n",
        "  sentences_by_cc.append(getter_i.sentences)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHk7lnAZ2gT_",
        "colab_type": "text"
      },
      "source": [
        "['T1', 'MORFOLOGIA_NEOPLASIA 2719 2740', 'Carcinoma microcítico\\n']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U6aOQD0AJDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_index = 0\n",
        "sent_index = 0\n",
        "ann = []\n",
        "for cc in range(len(sentences_by_cc)):\n",
        "#for cc in range(1):\n",
        "  file_index = file_index + 1\n",
        "  entity_counter = 0\n",
        "  ann_f = []\n",
        "  for sent in range(len(sentences_by_cc[cc])):\n",
        "    sent_index = sent_index + 1\n",
        "    skip_w = 0\n",
        "    for word in range(len(sentences_by_cc[cc][sent])): \n",
        "      try:\n",
        "        w = sentences_by_cc[cc][sent][word+skip_w]\n",
        "        if str(w[2])!='nan' and w[2]!='O': \n",
        "          entity_counter = entity_counter + 1\n",
        "          text = w[0]\n",
        "          start_pos = w[1] \n",
        "          end_pos = w[1] + len(w[0]) - 1 \n",
        "          for ws in sentences_by_cc[cc][sent][word+skip_w+1:]:\n",
        "            if str(ws[2])=='nan' or ws[2]=='O' or ws[2]=='B-MOR':\n",
        "            #if ws[2]=='O':\n",
        "              break\n",
        "              \n",
        "            else:\n",
        "              text = text + ' ' + ws[0]\n",
        "              end_pos = end_pos + 1 + len(ws[0])\n",
        "              skip_w = skip_w + 1 # to skip this word in the next iteration of the outside loop\n",
        "\n",
        "          ann_f.append(['T'+str(entity_counter),'MORFOLOGIA_NEOPLASIA '+str(start_pos)+' '+str(end_pos+1),text+'\\n'])\n",
        "      except:\n",
        "        break\n",
        "\n",
        "        \n",
        "  ann.append(ann_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZn7vh3B_Q9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f1d3c3f-6020-49c5-e988-c1633394b50d"
      },
      "source": [
        "ann[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['T1', 'MORFOLOGIA_NEOPLASIA 659 669', 'neoplásica\\n'],\n",
              " ['T2', 'MORFOLOGIA_NEOPLASIA 779 801', 'ADK próstata Gleason 6\\n']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC0XCPFjFYlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_cc = [\"\".join([\"\\t\".join([word for word in sent]) for sent in cc]) for cc in ann]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TIlEv04DK-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3bcc92a5-c665-4b62-bf5b-1a753807ee64"
      },
      "source": [
        "sentences_cc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'T1\\tMORFOLOGIA_NEOPLASIA 767 779\\thipernefroma\\nT2\\tMORFOLOGIA_NEOPLASIA 1284 1296\\thipernefroma\\nT3\\tMORFOLOGIA_NEOPLASIA 1660 1670\\ttumoración\\nT4\\tMORFOLOGIA_NEOPLASIA 1718 1734\\tnefroma quístico\\nT5\\tMORFOLOGIA_NEOPLASIA 1783 1790\\ttumoral\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2ffu9hGzyWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "2f93b0d0-288e-4e54-8b3e-644227fcd352"
      },
      "source": [
        "sentences_cc[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'T1\\tMORFOLOGIA_NEOPLASIA 393 421\\tcarcinoma ductal infiltrante\\nT2\\tMORFOLOGIA_NEOPLASIA 440 446\\tT2N0M0\\nT3\\tMORFOLOGIA_NEOPLASIA 677 684\\ttumoral\\nT4\\tMORFOLOGIA_NEOPLASIA 714 744\\tmetastásicas supraclaviculares\\nT5\\tMORFOLOGIA_NEOPLASIA 1098 1105\\ttumoral\\nT6\\tMORFOLOGIA_NEOPLASIA 1218 1246\\tcarcinoma ductal infiltrante\\nT7\\tMORFOLOGIA_NEOPLASIA 1464 1483\\tmetástasis M1 óseas\\nT8\\tMORFOLOGIA_NEOPLASIA 1596 1614\\tafectación anexial\\nT9\\tMORFOLOGIA_NEOPLASIA 1884 1910\\tcáncer de mama metastásico\\nT10\\tMORFOLOGIA_NEOPLASIA 1912 1915\\tCMm\\nT11\\tMORFOLOGIA_NEOPLASIA 3350 3397\\tCarcinoma de mama ductal infiltrante estadio IV\\nT12\\tMORFOLOGIA_NEOPLASIA 4171 4178\\tgrado I\\nT13\\tMORFOLOGIA_NEOPLASIA 6198 6209\\tmetastásica\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW33U2VSnuDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "92848bcf-fe1f-404e-ccb4-119dd422d646"
      },
      "source": [
        "sentences_cc[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'T1\\tMORFOLOGIA_NEOPLASIA 393 421\\tcarcinoma ductal infiltrante\\nT2\\tMORFOLOGIA_NEOPLASIA 440 446\\tT2N0M0\\nT3\\tMORFOLOGIA_NEOPLASIA 677 684\\ttumoral\\nT4\\tMORFOLOGIA_NEOPLASIA 714 744\\tmetastásicas supraclaviculares\\nT5\\tMORFOLOGIA_NEOPLASIA 1098 1105\\ttumoral\\nT6\\tMORFOLOGIA_NEOPLASIA 1218 1246\\tcarcinoma ductal infiltrante\\nT7\\tMORFOLOGIA_NEOPLASIA 1464 1483\\tmetástasis M1 óseas\\nT8\\tMORFOLOGIA_NEOPLASIA 1596 1614\\tafectación anexial\\nT9\\tMORFOLOGIA_NEOPLASIA 1884 1910\\tcáncer de mama metastásico\\nT10\\tMORFOLOGIA_NEOPLASIA 1912 1915\\tCMm\\nT11\\tMORFOLOGIA_NEOPLASIA 3350 3397\\tCarcinoma de mama ductal infiltrante estadio IV\\nT12\\tMORFOLOGIA_NEOPLASIA 4171 4178\\tgrado I\\nT13\\tMORFOLOGIA_NEOPLASIA 6198 6209\\tmetastásica\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE1bdRGZC905",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9fc0ef2-fc5d-46c8-cbc3-7c9a3f6f49f1"
      },
      "source": [
        "files_txt_test[0] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drive/My Drive/Ejemplos NER - TFM/test-background-set-to-publish/S0004-06142005000100009-1.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zl_rQWakojt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42c6eb90-596f-43fe-8515-8922d16f26f6"
      },
      "source": [
        "len(sentences_cc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPsE8WxrlSvj",
        "colab_type": "text"
      },
      "source": [
        "### **Store the annotation files**\n",
        "\n",
        "Change the method_name based on the method's predictions being employed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "534uamRxlb-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "method_name = 'results_CRF/ann/'\n",
        "#method_name = 'results_BILSTM_ap1/ann/'\n",
        "#method_name = 'results_BILSTM_ap2/ann/'\n",
        "#method_name = 'results_BILSTM_ap3/ann/'\n",
        "#method_name = 'results_bert/annotations/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9kmdzpuC40H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_path = len('drive/My Drive/Ejemplos NER - TFM/test-background-set-to-publish/')\n",
        "\n",
        "for cc in range(len(sentences_cc)):\n",
        "  file_name = files_txt_test[cc][len_path:]\n",
        "  file_name = file_name[:-4] # remove .txt\n",
        "  file_name_full = path+ method_name + file_name + '.ann'\n",
        "  with open(file_name_full, 'w') as file:\n",
        "    file.write(sentences_cc[cc])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}